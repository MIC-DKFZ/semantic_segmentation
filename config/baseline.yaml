#@package _global_

# Default List
# defines which modules from which parameter group are used by default and in which order they are composed
defaults:
  - _self_
  - trainer: SemSeg
  - hyperparameters/default     # Load Default Hyperparameters
  - optional hyperparameters:   # (Optional) Overwrite defaults with the specific hyperparameter config
  - optimizer: SGD              # Optimizer
  - lr_scheduler: polynomial    # Learning rate scheduler
  - callbacks: default          # Callbacks
  - data_augmentation: default  # Data Augmentation
  - metric: mean_IoU            # Metric configuration
  - dataset: Cityscapes         # Dataset
  - model: hrnet                # Model
  - environment: local          # Environment

  - override hydra/hydra_logging: colorlog    # Using colorlog plugin of hydra for logging
  - override hydra/job_logging: colorlog

# Logging Related Parameters
ORG_CWD: ${hydra:runtime.cwd}   # Saving the original working dir
experiment: "baseline"          # Possibility for naming the experiment
LOGDIR: logs/                   # Default logging directory
num_example_predictions: 5      # Save some example predictions during validation/testing
                                # Just for visualization/inspection, set to 0 if not wanted




# Customizations of Hydra

hydra:
  output_subdir: hydra
  run:
    dir: ${LOGDIR}/${DATASET.NAME}/${MODEL.NAME}/${experiment}__${path_formatter:${hydra.job.override_dirname}}/${now:%Y-%m-%d_%H-%M-%S}
    # Example Dir: /.../Semantic_Segmentation/logs/Cityscapes/hrnet/baseline__lossfunction_CE/2022-02-14_15-42-43/<ouputs>
    # using path_formatter with is defined in main.py to resolve problems which may occur with characters like [,],",or ',' in paths
  sweep:
    dir: multi_run_${hydra.run.dir}
    subdir: ${hydra.job.num}
  #job_logging:
  #  disable_existing_loggers: mmcv
  job:
    chdir: True
    config:
      override_dirname:
        kv_sep: "_"         # do not use "=" to prevent problems when parsing paths
        item_sep: "__"
        exclude_keys:       # excluding some key from ${hydra.job.override_dirname}
          - model           # already used in the path
          - dataset         # already used in the path
          - environment     # no needed information for the experiments
          - finetune_from   # to long
          - continue_from   # to long
          - experiment      # already used in the path
          - LOGDIR          # no needed information for the experiments

# Defining the datamodule
datamodule:
  _target_: datasets.DataModules.BaseDataModule   # Base Data Module
  num_workers: ${num_workers}      # Parsing all needed hyperparameters
  batch_size: ${batch_size}
  val_batch_size: ${val_batch_size}
  augmentations: ${AUGMENTATIONS} # Parsing the Data augmentation, defined in the augmentation config
  dataset: ${dataset}             # Parsing the Dataset defined in the dataset config

# Defining the saving behavior. Only used when checkpointing is enabled in the pl_trainer
ModelCheckpoint:
  _target_: src.callbacks.customModelCheckpoint   # Custom checkpoint Callback with a few modifications
  monitor: "metric/${METRIC.NAME}"        # Name of the metric during logging
  mode: "max"                             # min or max: should be metric me maximised or minimized
  filename: 'best_epoch_{epoch}__${METRIC.NAME}_{metric/${METRIC.NAME}:.4f}'
  auto_insert_metric_name: False          # Needs to be false for better naming of checkpoint
  save_last: True                         # If the last checkpoint should be saved too