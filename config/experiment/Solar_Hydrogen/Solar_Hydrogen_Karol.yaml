#@package _global_

# Define which Modelm, Dataset and  augmentation pipeline to use, additionally for instance segmentation
# another trainer and another metric have to be selected
defaults:
  - override /data_augmentation: randaugment_crop_flip
  - override /metric: MAP
  - override /trainer: InstSeg
  - override /dataset: Solar_Hydrogen_Karol
  - override /model: Mask_RCNN

# Configure the augmentation pipeline
AUGMENTATIONS:
  mean: [ 0.485, 0.456, 0.406 ]
  std: [ 0.229, 0.224, 0.225 ]
  crop_size: [300, 1920]
  N: 3
  M: 3

pl_trainer:
  enable_checkpointing: True   #Disable checkpointing on this environment
# Modify the saving behavior. Only used when checkpointing is enabled in the pl_trainer
ModelCheckpoint:
  save_weights_only: True                 # only save state_dict

# Hyperparameters for the Dataset
batch_size: 2                   # batch size per gpu for training
val_batch_size: ${batch_size}   # batch size per gpu for validation
epochs: 200                     # number of epochs
lr: 0.005                       # learning rate for training (0.01445439770745928)
momentum: 0.9                   # momentum for optimizer
weight_decay: 0.0005            # wd for optimizer

# Modify the logging behaviour, how many example predictions should be logged
num_example_predictions: 3
