# @package _global_

# Basic experiment for training. For some experiments (Cityscapes, VOC2010_Context they are
# overwritten in config/experiment/*.yaml, so edit the parameters there if using these datasets
num_workers: 10                 # number of workers for dataloader
batch_size: 6                   # batch size per gpu for training
val_batch_size: ${batch_size}   # batch size per gpu for validation
epochs: 400                     # number of eposchs
lr: 0.01                        # learning rate for training (0.01445439770745928)
momentum: 0.9                   # momentum for optimizer
weight_decay: 0.0005            # wd for optimizer
lossfunction: [ "CE", "CE", "CE", "CE"]     # list of lossfunctions
lossweight:   [1.0, 0.4, 0.05, 0.05]        # corresponding weights for each loss function
#seed: 1234                    # seed everything
pl_trainer:                     # parameters for the pytorch lightning trainers
  accelerator: 'gpu'            # train on GPU
  devices: -1                   # using all available GPUs
  max_epochs: ${epochs}         # parsing the number of epochs which is defined as a hyperparameter
  precision: 16                 # using Mixed Precision
  benchmark: True               # using benchmark for faster training
  deterministic: False          # deterministic does not work because of not deterministc CrossEntropyLoss Error - use "warn" instead
  enable_checkpointing: True    # Enable/Disable Checkpointing
  # Some usefull pl parameters for debugging
  #limit_train_batches: 0.1
  #limit_val_batches: 0.5
  #limit_test_batches: 0.25
  #accumulate_grad_batches: 2