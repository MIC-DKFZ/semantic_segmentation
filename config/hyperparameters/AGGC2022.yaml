#@package _global_
batch_size: 24                #batch size per gpu for training
val_batch_size: ${batch_size}   #batch size per gpu for validation
epochs: 20                    #number of eposchs
#lr: 0.001 #0.004                       #learning rate for training (0.01445439770745928)
lossfunction: [ "CE"] #, "CE", "CE", "CE"]     #list of lossfunctions
#lossweight:   [1.0, 0.4, 0.05, 0.05]        #corresponding weights for each loss function
#weight_decay: 0.0001            #wd for optimizer
#momentum: 0.9                   #momentum for optimize
pl_trainer:
  check_val_every_n_epoch: 4
#  limit_train_batches: 0.01
#  limit_val_batches: 0.01