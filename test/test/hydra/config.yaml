experiment: inference_time
num_gpus: null
num_workers: 12
batch_size: 6
val_batch_size: 1
epochs: 400
optimizer: sgd
lr_scheduler: poly
lr: 0.01
wd: 0.0005
momentum: 0.9
lossfunction:
- wCE
- wCE
- wCE
- wCE
lossweight:
- 1.0
- 0.4
- 0.05
- 0.05
pl_trainer:
  precision: 16
  sync_batchnorm: true
  benchmark: true
  enable_checkpointing: false
MODEL:
  PRETRAINED: true
  INIT_WEIGHTS: true
  ADAPTED_PRETRAINED_WEIGHTS: ${hydra:runtime.cwd}/${MODEL.PRETRAINED_WEIGHTS}
  NAME: hrnet_ocr_ms
  PRETRAINED_WEIGHTS: pretrained/hrnetv2_w48_imagenet_pretrained.pth
  MSCALE_OFFSET: 0.75
  MSCALE_TRAINING: true
  ALIGN_CORNERS: true
  MSCALE_LO_SCALE: 0.5
  SEGATTN_BOT_CH: 256
  N_SCALES:
  - 0.5
  - 1.0
  - 2.0
  MSCALE_DROPOUT: false
  MSCALE_INNER_3x3: true
  OCR:
    MID_CHANNELS: 512
    KEY_CHANNELS: 256
    DROPOUT: 0.05
    SCALE: 1
  EXTRA:
    FINAL_CONV_KERNEL: 1
    STAGE1:
      NUM_MODULES: 1
      NUM_RANCHES: 1
      BLOCK: BOTTLENECK
      NUM_BLOCKS:
      - 4
      NUM_CHANNELS:
      - 64
      FUSE_METHOD: SUM
    STAGE2:
      NUM_MODULES: 1
      NUM_BRANCHES: 2
      BLOCK: BASIC
      NUM_BLOCKS:
      - 4
      - 4
      NUM_CHANNELS:
      - 48
      - 96
      FUSE_METHOD: SUM
    STAGE3:
      NUM_MODULES: 4
      NUM_BRANCHES: 3
      BLOCK: BASIC
      NUM_BLOCKS:
      - 4
      - 4
      - 4
      NUM_CHANNELS:
      - 48
      - 96
      - 192
      FUSE_METHOD: SUM
    STAGE4:
      NUM_MODULES: 3
      NUM_BRANCHES: 4
      BLOCK: BASIC
      NUM_BLOCKS:
      - 4
      - 4
      - 4
      - 4
      NUM_CHANNELS:
      - 48
      - 96
      - 192
      - 384
      FUSE_METHOD: SUM
datamodule:
  _target_: datasets.DataModules.BaseDataModule
  num_workers: ${num_workers}
  batch_size: ${batch_size}
  val_batch_size: ${val_batch_size}
  augmentations: ${AUGMENTATIONS}
  train_size: ${DATASET.SIZE.TRAIN}
  dataset: ${dataset}
CALLBACKS:
  time_callback:
    _target_: utils.callbacks.TimeCallback
  lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: step
  tqdm_progressbar:
    _target_: pytorch_lightning.callbacks.progress.TQDMProgressBar
    refresh_rate: 100
  model_summary:
    _target_: pytorch_lightning.callbacks.ModelSummary
    max_depth: 2
  model_checkpoint: null
  ms_restriction_callback:
    _target_: utils.callbacks.MS_RestictionCallback
    ms_offset: ${MODEL.MSCALE_OFFSET}
    m_scale_training: ${MODEL.MSCALE_TRAINING}
    epochs: ${epochs}
AUGMENTATIONS:
  TEST:
  - Compose:
      transforms:
      - Normalize:
          mean:
          - 0.485
          - 0.456
          - 0.406
          std:
          - 0.229
          - 0.224
          - 0.225
      - ToTensorV2: null
  TRAIN:
  - Compose:
      transforms:
      - RandomScale:
          scale_limit:
          - -0.5
          - 1.0
          p: 1.0
      - RandomCrop:
          height: 512
          width: 1024
      - HorizontalFlip:
          p: 0.5
      - Normalize:
          mean:
          - 0.485
          - 0.456
          - 0.406
          std:
          - 0.229
          - 0.224
          - 0.225
      - ToTensorV2: null
extra_testing: true
dataset:
  _target_: datasets.Cityscapes.Cityscapes_dataset
  root: ${paths.cityscapes}
DATASET:
  NAME: Cityscapes
  NUM_CLASSES: 19
  IGNORE_INDEX: 255
  SIZE:
    TRAIN: 2975
    VAL: 500
    TEST: 1525
  CLASS_WEIGHTS:
  - 0.8373
  - 0.918
  - 0.866
  - 1.0345
  - 1.0166
  - 0.9969
  - 0.9754
  - 1.0489
  - 0.8786
  - 1.0023
  - 0.9539
  - 0.9843
  - 1.1116
  - 0.9037
  - 1.0865
  - 1.0955
  - 1.0865
  - 1.1529
  - 1.0507
  CLASS_LABELS:
  - road
  - sidewalk
  - building
  - wall
  - fence
  - pole
  - traffic light
  - traffic sign
  - vegetation
  - terrain
  - sky
  - person
  - rider
  - car
  - truck
  - bus
  - train
  - motorcycle
  - bicycle
LOGDIR: logs/
paths:
  cityscapes: /home/l727r/Desktop/Datasets/cityscapes
  VOC2010_Context: /home/l727r/Desktop/Datasets/VOC2010_Context
